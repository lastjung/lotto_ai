"""
GAN ë¡œë˜ ë²ˆí˜¸ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
"""

import torch
import argparse
from pathlib import Path
import json

from models.gan.gan import create_generator

CONFIG_PATH = Path(__file__).parent / 'config.json'

def load_config():
    with open(CONFIG_PATH, 'r') as f:
        return json.load(f)



from models.transformer.transformer import create_model as create_transformer
from models.transformer.dataloader_bonus import get_latest_bonus_sequence

def generate_numbers(config, num_sets: int = None):
    model_cfg = config['model']
    gen_cfg = config['generation']
    paths_cfg = config['paths']
    
    num_sets = num_sets or gen_cfg['sets']
    
    # ë””ë°”ì´ìŠ¤
    if torch.backends.mps.is_available():
        device = torch.device('mps')
    elif torch.cuda.is_available():
        device = torch.device('cuda')
    else:
        device = torch.device('cpu')
    
    # GAN ëª¨ë¸ ë¡œë“œ
    checkpoint = torch.load(paths_cfg['checkpoint_g'], map_location=device, weights_only=False)
    saved_config = checkpoint.get('config', model_cfg)
    
    generator = create_generator(saved_config).to(device)
    generator.load_state_dict(checkpoint['generator_state_dict'])
    generator.eval()
    
    # ë³´ë„ˆìŠ¤ ëª¨ë¸ ë¡œë“œ (Transformer)
    bonus_config_path = Path(__file__).parent.parent / 'transformer' / 'config_bonus.json'
    with open(bonus_config_path, 'r') as f:
        bonus_cfg = json.load(f)
    
    bonus_model_path = bonus_cfg['paths']['checkpoint']
    bonus_ckpt = torch.load(bonus_model_path, map_location=device, weights_only=False)
    bonus_model = create_transformer(bonus_ckpt.get('config', bonus_cfg['model'])).to(device)
    bonus_model.load_state_dict(bonus_ckpt['model_state_dict'])
    bonus_model.eval()
    
    # ë³´ë„ˆìŠ¤ ì…ë ¥ ì‹œí€€ìŠ¤
    bonus_data_path = bonus_cfg['paths']['data']
    bonus_seq = get_latest_bonus_sequence(bonus_data_path, bonus_cfg['model']['seq_len']).to(device)
    
    print('=' * 60)
    print('ğŸ± AI ë¡œë˜ ë²ˆí˜¸ ìƒì„±ê¸° (GAN + Bonus Transformer)')
    print('=' * 60)
    print(f'   GAN ëª¨ë¸: {paths_cfg["checkpoint_g"]}')
    print(f'   ë³´ë„ˆìŠ¤ ëª¨ë¸: {bonus_model_path}')
    print('=' * 60)
    
    generated = generator.generate(num_sets, device)
    results = []
    
    # ë³´ë„ˆìŠ¤ ë²ˆí˜¸ ìƒì„± (í•˜ì´ë¸Œë¦¬ë“œ)
    for i in range(num_sets):
        main_nums = generated[i]
        main_list = main_nums.cpu().tolist()
        
        # ë³´ë„ˆìŠ¤ ì˜ˆì¸¡
        bonus_input = bonus_seq.repeat(1, 1, 1)
        with torch.no_grad():
            bonus_logits = bonus_model.forward(bonus_input)
            bonus_probs = bonus_logits[0, 0, :]
            
            # ë©”ì¸ ë²ˆí˜¸ ë§ˆìŠ¤í‚¹ (1e9 ëº„ì…ˆìœ¼ë¡œ í™•ë¥  0 ë§Œë“¦)
            for num in main_list:
                bonus_probs[num - 1] = -float('inf')
                
            probs = torch.softmax(bonus_probs, dim=-1)
            bonus_idx = torch.multinomial(probs, 1).item()
            bonus = bonus_idx + 1
            
        results.append((main_list, bonus))
    
    print('\nğŸ“Œ ìƒì„±ëœ ë²ˆí˜¸:')
    print('-' * 60)
    
    for i, (nums, bonus) in enumerate(results):
        nums_str = ', '.join([f'{n:2d}' for n in nums])
        print(f'   ì„¸íŠ¸ {i+1}: [ {nums_str} ] + ë³´ë„ˆìŠ¤ ğŸ”µ {bonus}')
    
    print('-' * 60)
    print('\nğŸ’¡ ì°¸ê³ : AI ì˜ˆì¸¡ì€ ì¬ë¯¸ìš©ì´ë©° ë‹¹ì²¨ì„ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.')
    
    return results


def main():
    config = load_config()
    gen_cfg = config['generation']
    
    parser = argparse.ArgumentParser(description='GAN ë¡œë˜ ë²ˆí˜¸ ìƒì„±')
    parser.add_argument('--sets', type=int, default=gen_cfg['sets'], help='ìƒì„±í•  ì„¸íŠ¸ ìˆ˜')
    args = parser.parse_args()
    
    generate_numbers(config, num_sets=args.sets)


if __name__ == '__main__':
    main()
